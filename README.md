# ğŸ¤– Autonomous AI Agent for Document Intelligence
RAG-Powered | FAISS | Groq LLaMA 3.1 | LangGraph
<p align="center"> <img src="https://img.shields.io/badge/AI-Agent-blueviolet?style=for-the-badge" /> <img src="https://img.shields.io/badge/RAG-Enabled-success?style=for-the-badge" /> <img src="https://img.shields.io/badge/FAISS-VectorDB-orange?style=for-the-badge" /> <img src="https://img.shields.io/badge/Groq-LLM-black?style=for-the-badge" /> <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge" /> </p> <p align="center"> <b>An end-to-end Autonomous AI Agent that performs document-grounded reasoning using Retrieval-Augmented Generation (RAG).</b> </p>

## ğŸ“‘ Table of Contents

ğŸ‘‰ Clicking any item below will auto-scroll on GitHub

- [Project Overview](#-project-overview)
- [Project Structure](#-project-structure)
- [Key Capabilities](#-key-capabilities)
- [System Architecture](#-system-architecture)
- [Tech Stack](#ï¸-tech-stack)
- [Setup Instructions](#ï¸-setup-instructions)
- [Document Ingestion](#-document-ingestion-vector-store-creation)
- [Running the Autonomous AI Agent](#-run-the-autonomous-ai-agent)
- [Execution Screenshots](#-execution-screenshots)
- [Future Enhancements](#-future-enhancements)
- [Author](#-author)


## ğŸš€ Project Overview

This project implements a production-style Autonomous AI Agent capable of answering questions strictly based on uploaded documents.

Instead of relying only on model memory, the agent:

Retrieves relevant document context

Grounds responses using a vector database

Uses LLM reasoning only after retrieval

This mirrors real enterprise GenAI systems used in:

Document intelligence

Compliance & policy Q&A

Research assistants

Internal knowledge systems

ğŸ“‚ Project Structure
```
autonomous-ai-agent-document-intelligence/
â”‚
â”œâ”€â”€ agent/               # Agent logic & orchestration
â”‚   â”œâ”€â”€ graph.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ state.py
â”‚   â””â”€â”€ tools.py
â”‚
â”œâ”€â”€ rag/                 # RAG pipeline
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â””â”€â”€ embeddings.py
â”‚
â”œâ”€â”€ llm/                 # Groq LLM configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_docs/
â”‚   â””â”€â”€ vectorstore/
â”œâ”€â”€ screenshots/
â”œâ”€â”€ ui/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## âœ¨ Key Capabilities

Autonomous agent orchestration using LangGraph

Retrieval-Augmented Generation (RAG)

Semantic document ingestion and chunking

FAISS vector search for fast retrieval

HuggingFace MiniLM embeddings

Groq LLaMA 3.1 for low-latency inference

Modular, extensible architecture

CLI-based interactive querying

## ğŸ§  System Architecture
User Query
   â†“
Autonomous AI Agent
   â†“
RAG Tool Invocation
   â†“
FAISS Vector Store
   â†“
Relevant Document Chunks
   â†“
Groq LLM (Grounded Answer)


âœ” Prevents hallucination
âœ” Answers strictly from documents
âœ” Agent decides when to retrieve

## ğŸ› ï¸ Tech Stack
Layer	Technology
Language	Python 3.10+
Agent Framework	LangGraph
RAG Framework	LangChain
Vector Database	FAISS
Embeddings	HuggingFace (all-MiniLM-L6-v2)
LLM	Groq â€“ LLaMA 3.1
Environment	Virtualenv
Version Control	Git & GitHub

## âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository
git clone https://github.com/ajinkya0771/autonomous-ai-agent-document-intelligence.git
cd autonomous-ai-agent-document-intelligence

2ï¸âƒ£ Create & Activate Virtual Environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Configure Environment Variables

Create a .env file:

GROQ_API_KEY=your_groq_api_key_here

ğŸ“¥ Document Ingestion (Vector Store Creation)
python -m rag.run_ingest


Loads documents

Splits into chunks

Generates embeddings

Stores vectors in FAISS

ğŸ¤– Run the Autonomous AI Agent
python main.py


Example:

Ask a question:
Based only on the uploaded document, explain what Retrieval-Augmented Generation is.


âœ” Agent invokes retrieval tool
âœ” Fetches relevant context
âœ” Generates grounded answer

## ğŸ“¸ Execution Screenshots
Step	Description
01	Project structure
02	Virtual environment activated
03	Vector store created
04	Autonomous agent started
05	Direct LLM response
06	RAG tool invocation
07	Document-grounded answer
ğŸ”® Future Enhancements

Multi-Level / Hierarchical RAG

Tool routing based on intent

Metadata-aware retrieval

Memory-enabled agents

Web UI (Streamlit / FastAPI)

Enterprise document pipelines

## ğŸ“Œ Author

Ajinkya Dhote
AI / GenAI Engineer
GitHub: https://github.com/ajinkya0771
